# PG知识点整理

## PG有哪些大型的分支版本？

- postgres-xc/xl
- pipelinedb
- greenplum

插件：

- postgis
- pgbouncer
- pgpath
- postgrest
- pgpool

## PG的存储引擎简单介绍一下？



## PG的物理文件如何存储？



## 通过PG处理过哪些案例？



1. mysql版本的升级
2. 处理mysql集群的各种坑和问题
3. 根据公司业务类型，设计合理mysql库，表，架构。
4. 定期进行灾备恢复演练
5. 误删除数据之后，恢复数据



## PG锁机制简单介绍一下？



死锁



## 服务器负载过高或者网页打开缓慢，简单说说你的优化思路 ？

1. 首先我们要发现问题的过程，通过操作系统，数据库，程序设计，硬件角度四个维度找到问题所在
2. 找到瓶颈点的位置
3. 制定好优化方案，形成处理问题的体系
4. 体系制定好之后，在测试环境进行优化方案的测试
5. 测试环境如果优化效果很好，再实施到生产环境
6. 做好处理问题的记录



- 扩大虚拟内存，并保证有足够的可以扩充的空间
- 关闭数据库服务器上不必要的服务
- 数据库服务器和主域服务器分开
- 数据库服务器的吞吐量调为最大



- 只建立一个聚簇索引
- 为经常查询的列都建立索引
- 不要建立太多的索引
- 避免为大型数据类型的列建立索引



- 尽量使用存储过程



## 如何优化一条有问题的sql语句？

针对sql语句的优化，我们不要上来就回答添加索引，这样显得太不专业。我们可以从如下几个角度去分析

1. 回归到表的设计层面，数据类型选择是否合理
2. 大表碎片的整理是否完善
3. 表的统计信息，是不是准确的
4. 审查表的执行计划，判断字段上面有没有合适的索引
5. 针对索引的选择性，建立合适的索引（就又涉及到大表DDL的操作问题）



## 大表DDL语句，如何实施，才能把性能影响降到最低？

1. 可以通过传统方法导入导出数据，新建一张与原表一样的表结构，把需要执行的ddl语句在无数据的新表执行，然后把老表中的数据导入到新表中，把新表改成老表的名字
2. 通过第三方工具 业界中的瑞士×××percona-toolkit中的命令，pt-online-schema-change进行在线操作
3. 对于新版本的mysql（5.7）可以直接在线online ddl



## 如何监控mysql  replication复制延迟？

1. 可以通过第三方工具 业界中的瑞士×××percona-toolkit中的命令，pt-heartbeat进行主从延迟监控。
2. 传统方法，通过比较主从服务器之间的position号的差异值。
3. 还可以通过查看seconds_behind_master估算一下主从延迟时间



## PG主从复制的具体原理是什么？



## PG有哪些索引类型？



## 使用索引查询一定能提高查询的性能吗，为什么？

通常,通过索引查询数据比全表扫描要快，但是我们也必须注意到它的代价。

索引需要空间来存储,也需要定期维护，每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的INSERT,DELETE,UPDATE将为此多付出4，5 次的磁盘I/O。因为索引需要额外的存储空间和处理,那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况：

- 基于一个范围的检索，一般查询返回结果集小于表中记录数的30%
- 基于非唯一性索引的检索



## 说一说索引的优缺点和使用原则？

优点：

1. 将随机I/O变为顺序I/O，大大加快检索速度
2. 创建唯一性索引，保证数据库表中每一行数据的唯一性
3. 加速表和表之间的连接
4. 在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间

缺点：

1. 索引需要占用数据表以外的物理存储空间
2. 创建索引和维护索引要花费一定的时间
3. 当对表进行更新操作时，索引需要被重建，这样降低了数据的维护速度。

使用原则：

1. 不要索引数据量不大的表，对于小表来讲，表扫描的成本并不高。
2. 不要设置过多的索引，在没有聚集索引的表中，最大可以设置249个非聚集索引，过多的索引首先会带来更大的磁盘空间，而且在数据发生修改时，对索引的维护是特别消耗性能的。
3. 合理应用复合索引，有某些情况下可以考虑创建包含所有输出列的复合索引。
4. 对经常使用范围查询的字段，可能考虑聚集索引。
5. 避免对不常用的列，逻辑性列，大字段列创建索引。



## PG的索引类型和实现原理？

- B-tree
  - 适用情况：< <= = >= > between in / is null / is not null / like 'foo%' / ~ '^foo'（开头是固定的）
- Hash( CREATE INDEX name ON table USING HASH (column) ) （不记日志，淘汰）
  - 试用情况：等值比较
- GiST
- SP-GiST
- GIN
  - 适用情况：测试数组中是否存在某个值 <@  |  @>  |  =  |  &&
- BRIN 



## 来，手写一个红黑树看看



## 索引失效的原因？

- 对单字段建立索引，where条件多字段
- 复合索引失效，where条件没有按照符合索引的顺序排列
- 对索引列运算，运算符包括（+、-、*、/、！、<>、%、like'%_'（%放在前面）、or、in、exist等），比如where a+1=c
- 类型错误，字段类型为varchar，where条件用number
- 对索引使用内部函数，这种情况下应该建立基于函数的索引
- where子句中使用参数，select id from t where num=@num



## PG是怎样保证ACID的？

**原子性（Atomicity）：**一个事务（Transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。

PG保证：事务。



**一致性（Consistency）：**在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的默认规则，这包含资料的精准度、串联新以及后续数据库可以自发性地完成预定的工作。A转账给B，执行事务之前：A+B=100，执行事务之后：A+B=100

PG保证：事务。



**隔离性（Isolation）：**当两个或者多个事务并发访问（此处访问指查询和修改的操作）数据库的同一数据时所表现出的互相关系。事务隔离分为不同的级别，包括读不提交（Read uncommitted）、读提交（Read committed）、可重复读（Repeatable read）和串行化（Serializable）。多个事务并发访问相互之间不影响，A事务的结果不会覆盖B事务的结果

PG保证：MVCC。



**持久性（Durability）：**在事务完成以后，该事务对数据库所作的更改便持久地保存在数据库之中，而且是完全的。事务一旦提交，对数据库数据的改变就是永久性的。

Pg保证：WAL。



## 说一说**delete**与**truncate**的区别？

- TRUNCATE可以从一组表中快速地移除所有行。 它具有和在每个表上执行无条件DELETE相同的效果，不过它会更快，因为它没有实际扫描表。此外，它会立刻回收磁盘空间， 而不是要求一个后续的VACUUM操作。在大表上它最有用。
- TRUNCATE在要操作的表上要求一个 ACCESS EXCLUSIVE（8级）锁，这会阻塞所有其他在该表上的并发操作。当指定RESTART IDENTITY时，任何需要被 重新开始的序列也会被排他地锁住。如果要求表上的并发访问，那么 应该使用DELETE命令。
- DELETE加三级锁：ROW EXCLUSIVE。



## 超键、候选键、主键、外键分别是什么？

- 超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。
- 候选键：是最小超键，即没有冗余元素的超键。
- 主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。
- 外键：在一个表中存在的另一个表的主键称此表的外键。



## 什么是视图？以及视图的使用场景有哪些？

视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。

- 只暴露部分字段给访问者，所以就建一个虚表，就是视图。
- 查询的数据来源于不同的表，而查询者希望以统一的方式查询，这样也可以建立一个视图，把多个表查询结果联合起来，查询者只需要直接从视图中获取数据，不必考虑数据来源于不同表所带来的差异

## 说一说三个范式？

- 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。
- 第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。 
- 第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在"A → B → C"的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y



## **SQL 约束有哪几种？**

- NOT NULL: 用于控制字段的内容一定不能为空（NULL）。 
- UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。
- PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。
- FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
- CHECK: 用于控制字段的值范围。
  - DEFAULT: 用于设置新记录的默认值。



## 如何避免sql注入，

- sql注入：用户输入的数据，未经检测，变成了sql语句的一部分，造成意外的结果输出。
- 避免sql注入：避免数据变成代码被执行，对sql语句进行预编译和查询参数绑定，在SQL语句中放置占位符'?'，然后将带有占位符的SQL语句传给数据库编译，执行的时候才将用户输入的数据作为执行的参数传给用户。这样的操作不仅使得SQL语句在书写的时候不再需要拼接，看起来也更直接，而且用户输入的数据也没有机会被送到数据库的SQL解释器被编译执行，也不会越权变成代码。



## 数据库的乐观锁和悲观锁？

- 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作
- 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。

**悲观锁：**每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。比较适合写入操作比较频繁的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。

**乐观锁：**每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。

**应用场景：**读取频繁使用乐观锁，写入频繁使用悲观锁。



## inner join,left join,right join的区别？

- inner join：交集。
- left join：左全集+右面符合where的数据，右面有多条匹配会产生多行。
- right join：右全集+左面符合where的数据，没有则空。
- full join：两面符合where的数据+匹配不上的为空的数据。



## 数据库中某个表查询和存取数据量很大时怎么处理？

